# Copyright (C) 2017 NVIDIA Corporation.  All rights reserved.
# Licensed under the CC BY-NC-SA 4.0 license (https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode).

# logger options
image_display_iter: 50       # How often do you want to display output images during training
display_size: 1              # How many images do you want to display each time
snapshot_save_iter: 5        # How often do you want to save trained models
latest_save_iter: 1          # How often do you want to save trained models
log_iter: 201                # How often do you want to log the training stats
log_dir: './logs'          # Log prefix to save checkpoints
pretrained:  ''              # Start from specified checkpoint if not ''
gpu_ids: '4'

# optimization options
n_epoch: 100                   # maximum number of training epochs
n_iterations: 1
batch_size: 32                 # batch size
weight_decay: 0.0001          # weight decay
beta1: 0.5                    # Adam parameter
beta2: 0.999                  # Adam parameter
init: gaussian                # initialization [gaussian/kaiming/xavier/orthogonal]
lr: 0.00005                   # initial learning rate
lr_policy: step               # learning rate scheduler
step_size: 100000             # how often to decay learning rate
gamma: 0.5                    # how much to decay learning rate

l1_w : 100.                   # weight of L1 loss
gan_w: 1.                     # weight of DCGAN loss
multimodal_b0: 7              # input channel: b0
multimodal_t1: 1              # input channel: T1
multimodal_t2: 0              # input channel: T2

# model options
gen:
  dim: 64                     # number of filters in the bottommost layer
  mlp_dim: 256                # number of filters in MLP
  style_dim: 4                # length of direction
  activ: relu                 # activation function [relu/lrelu/prelu/selu/tanh]
  n_downsample: 2             # number of downsampling layers in content encoder
  n_res: 4                    # number of residual blocks in content encoder/decoder
  pad_type: reflect           # padding type [zero/reflect]
  g_type: resnet
dis:
  in_dim: 9                   # number of input images: b0 + t1 + t2(not yet) + fake dwi
  lr_d: 0.00005
  dim: 64                     # number of filters in the bottommost layer
  norm: none                  # normalization layer [none/bn/in/ln]
  activ: lrelu                # activation function [relu/lrelu/prelu/selu/tanh]
  n_layer: 2                  # number of layers in D
  gan_type: lsgan             # DCGAN loss [lsgan/nsgan]
  num_scales: 1               # number of scales
  pad_type: reflect           # padding type [zero/reflect]
  d_type: unet                # Discriminator type [Unet]

# data options
input_dim: 8                  # number of image channels [1 - 3]: b0, t1, t2
output_dim: 1
num_workers: 4                # number of data loading threads
pad_size: 160                # random crop image size
#data_root: /scratch/connectome/GANBERT/data/sample_final       # dataroot of training files
data_root: /storage/connectome/GANBERT/data/sample/sample_b0_input_ver       # dataroot of training files

# dataset folder location
dataset:  ABCD
n_dwi: 2
img_dir: /home/connectome/conmaster/Pycharm_projects/3D_brain2brain_GAN/Benchmark_2D/Generated_images/b0_input
